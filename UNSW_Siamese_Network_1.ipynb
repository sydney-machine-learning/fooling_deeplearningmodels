{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNSW-Siamese_Network-1",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07168e707d45427c9841325f132f55ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60acbfa7b472499d9a74794b9da9993b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_97af262c2d1d4a6694edbb5b3ff0454a",
              "IPY_MODEL_9b444a315800467ba1e8edaa5a02daf5"
            ]
          }
        },
        "60acbfa7b472499d9a74794b9da9993b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97af262c2d1d4a6694edbb5b3ff0454a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ab18d7031e644f8abfaca093176df5f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 40,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 40,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e04c72928da647d7af1dbb4700852f59"
          }
        },
        "9b444a315800467ba1e8edaa5a02daf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b2c704682416490c99bca9d4d44b8226",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 40/40 [02:15&lt;00:00,  3.39s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f904904015d4e17aa4c693bcccb77f4"
          }
        },
        "9ab18d7031e644f8abfaca093176df5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e04c72928da647d7af1dbb4700852f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2c704682416490c99bca9d4d44b8226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f904904015d4e17aa4c693bcccb77f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4c84cebcfab410fa63bcf15b5cc809f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4671b666ca744887b3278c240f076948",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fac4de927c774b08915e0e3d087bc3eb",
              "IPY_MODEL_905114d777964d7d81f3acb151932a22"
            ]
          }
        },
        "4671b666ca744887b3278c240f076948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fac4de927c774b08915e0e3d087bc3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c350e54ad7e6468aa0f3b08ad9e9b107",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 15,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 15,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c2aedef78a8435599e44fde34a42132"
          }
        },
        "905114d777964d7d81f3acb151932a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67662d4986e64d168d954dd63ac7d1a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 15/15 [00:10&lt;00:00,  1.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c65e1ff077649a1b28a6f516249fee4"
          }
        },
        "c350e54ad7e6468aa0f3b08ad9e9b107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c2aedef78a8435599e44fde34a42132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67662d4986e64d168d954dd63ac7d1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c65e1ff077649a1b28a6f516249fee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZASPeDyYjZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WE WILL BE TRAINING ON 40 CLASSES OUT OF 55 CLASSES (1-40)\n",
        "# THE REMAINING 15 CLASSES WILL BE LATER USED IN THE EVALUATION PHASE (41-55)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIm9jZeASKa8",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sAh-XWZRFqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "rng = np.random.default_rng()\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import initializers\n",
        "from keras import backend as K\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, UpSampling2D\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape, Flatten, Dense\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-BiqU50SSwO",
        "colab_type": "text"
      },
      "source": [
        "# PREPARING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M20m9z7Rb5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('/content/train'):\n",
        "  os.makedirs('/content/train')\n",
        "\n",
        "os.chdir('/content/drive/My Drive/UNSW-Intern')\n",
        "!unrar x '/content/drive/My Drive/UNSW-Intern/CEDAR-signatures.rar'  '/content/train'\n",
        "\n",
        "os.chdir('/content/train/signatures/full_org')\n",
        "!rm /content/train/signatures/full_org/Thumbs.db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujK7JXZyvqEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DEFINING THE PARAMETERS\n",
        "total_classes = 55\n",
        "num_classes = 40\n",
        "img_per_class = 24\n",
        "batch_size = 32\n",
        "img_height = 128\n",
        "img_width = 128"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPeJ_13pTBpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "07168e707d45427c9841325f132f55ce",
            "60acbfa7b472499d9a74794b9da9993b",
            "97af262c2d1d4a6694edbb5b3ff0454a",
            "9b444a315800467ba1e8edaa5a02daf5",
            "9ab18d7031e644f8abfaca093176df5f",
            "e04c72928da647d7af1dbb4700852f59",
            "b2c704682416490c99bca9d4d44b8226",
            "1f904904015d4e17aa4c693bcccb77f4",
            "f4c84cebcfab410fa63bcf15b5cc809f",
            "4671b666ca744887b3278c240f076948",
            "fac4de927c774b08915e0e3d087bc3eb",
            "905114d777964d7d81f3acb151932a22",
            "c350e54ad7e6468aa0f3b08ad9e9b107",
            "4c2aedef78a8435599e44fde34a42132",
            "67662d4986e64d168d954dd63ac7d1a5",
            "2c65e1ff077649a1b28a6f516249fee4"
          ]
        },
        "outputId": "4b3fa502-4039-404e-a34a-5337574a1ab5"
      },
      "source": [
        "# LOADING TRAINING IMAGES\n",
        "\n",
        "def get_images(path, train=True):\n",
        "  ids = os.listdir(path + '/full_org')\n",
        "  if train:\n",
        "    X = np.zeros((num_classes, img_per_class, img_height, img_width,1), dtype = np.float32)\n",
        "    y = np.zeros((img_per_class*num_classes,1))\n",
        "\n",
        "  else:\n",
        "    X = np.zeros((total_classes-num_classes, img_per_class, img_height, img_width, 1), dtype = np.float32)\n",
        "    y = np.zeros((img_per_class*(total_classes-num_classes),1))\n",
        "\n",
        "  if train:\n",
        "    print('Getting and resizing training images ... ')\n",
        "    for i in tqdm_notebook(range(num_classes)):\n",
        "      for j in range(img_per_class):\n",
        "        #Load Images\n",
        "        img = load_img(path + '/full_org/' + 'original_' + str(i+1) + '_' + str(j+1) + '.png', grayscale=True)\n",
        "        x_img = img_to_array(img)\n",
        "        #print(\"YOOOOOO \",x_img.shape)\n",
        "        x_img = resize(x_img, (img_height, img_width), mode = 'constant', preserve_range=True)\n",
        "        #print(\"YOOOOOO \",x_img.shape)\n",
        "        #Load Images\n",
        "        y1 = np.array([i+1])\n",
        "        # Save Images       \n",
        "        X[i,j,...] = x_img/255\n",
        "        #print(\"YOOOOOO \",X.shape)\n",
        "        y[i*img_per_class + j] = y1\n",
        "\n",
        "    else:\n",
        "      print('Getting and resizing validation images ... ')\n",
        "      for i in tqdm_notebook(range(total_classes-num_classes)):\n",
        "        for j in range(img_per_class):\n",
        "          #Load Images\n",
        "          img = load_img(path + '/full_org/' + 'original_' + str(i+1+num_classes) + '_' + str(j+1) + '.png', grayscale=True)\n",
        "          x_img = img_to_array(img)\n",
        "          #print(\"YOOOOOO \",x_img.shape)\n",
        "          x_img = resize(x_img, (img_height, img_width), mode = 'constant', preserve_range=True)\n",
        "          #print(\"YOOOOOO \",x_img.shape)\n",
        "          #Load Images\n",
        "          y1 = np.array([i+1+num_classes])\n",
        "          # Save Images       \n",
        "          X[i,j,...] = x_img/255\n",
        "          #print(\"YOOOOOO \",X.shape)\n",
        "          y[i*img_per_class + j] = y1       \n",
        "\n",
        "  X = np.squeeze(X,axis=-1)\n",
        "  print('Done!')\n",
        "  return X,y\n",
        "\n",
        "X_train,y_train = get_images('/content/train/signatures', True)\n",
        "X_valid,y_valid = get_images('/content/train/signatures', False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting and resizing training images ... \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07168e707d45427c9841325f132f55ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Getting and resizing validation images ... \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4c84cebcfab410fa63bcf15b5cc809f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done!\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUV8Cw2HSYhp",
        "colab_type": "text"
      },
      "source": [
        "# PREPARING PAIRS OF IMAGES FOR ONE SHOT LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AEp77BvN9VB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(X_train, batch_size, s='train'):\n",
        "\n",
        "  # Creating a batch of n pairs, half same class, half different class\n",
        "\n",
        "  if s == 'train':\n",
        "    X = X_train\n",
        "\n",
        "  n_classes, n_examples, h, w = X_train.shape\n",
        "\n",
        "  # Randomly sampling several classes to use in the batch\n",
        "  rng = np.random.default_rng()\n",
        "  categories = rng.choice(num_classes, size = (batch_size,), replace = False)\n",
        "\n",
        "  # Initialising two empty arrays for the input image batch\n",
        "  pairs = [np.zeros((batch_size, h, w, 1)) for i in range(2)] \n",
        "\n",
        "  # Initialising target vector\n",
        "  target = np.zeros((batch_size,))\n",
        "\n",
        "  # make one half of it '1s' and the other as '0s'\n",
        "  target[batch_size//2:] = 1\n",
        "  for i in range(batch_size):\n",
        "    category_1 = categories[i]\n",
        "    idx_1 = np.random.randint(0,n_examples)\n",
        "    pairs[0][i,:,:,:] = X[category_1,idx_1].reshape(h,w,1)\n",
        "\n",
        "    # Pick images of same class for 1st half, different for 2nd\n",
        "    idx_2 = np.random.randint(0,n_examples)\n",
        "    if i >= batch_size//2:\n",
        "      category_2 = category_1\n",
        "    else:\n",
        "      # add a random number to the category modulo n classes to ensure 2nd image has a different category\n",
        "      category_2 = (category_1 + np.random.randint(1,n_classes)) % (n_classes)\n",
        "\n",
        "    pairs[1][i,:,:,:] = X[category_2, idx_2].reshape(h,w,1)\n",
        "\n",
        "\n",
        "  return pairs, target\n",
        "\n",
        "\n",
        "#pairs,target = get_batch(X, batch_size,\"train\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NxnYkoSB8NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GENERATOR FUNCTION FOR THE GET_BATCH FUNCTION TO INPUT IN FIT.GENERATOR CALL\n",
        "\n",
        "def generate(Xtrain, batch_size, s = \"train\"):\n",
        "  while True:\n",
        "    pairs,target = get_batch(Xtrain,batch_size, s)\n",
        "    yield pairs,target\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM6SO6tHXcwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_weights(shape, name=None):\n",
        "    \"\"\"\n",
        "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
        "\n",
        "\n",
        "def initialize_bias(shape, name=None):\n",
        "    \"\"\"\n",
        "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYeBdHb8SoJl",
        "colab_type": "text"
      },
      "source": [
        "# DEFINING THE MODEL ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-8Xoz4hPRLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DEFINING THE MODEL ARCHITECTURE \n",
        "\n",
        "def get_siamese_model(input_shape):\n",
        "    \"\"\"\n",
        "        Model architecture\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the tensors for the two input images\n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "    \n",
        "    # Convolutional Neural Network\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
        "                   kernel_initializer=initializers.RandomNormal(stddev=0.01), kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (7,7), activation='relu',\n",
        "                     kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "                     bias_initializer=initializers.RandomNormal(mean=0.5,stddev=0.01), kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "                     bias_initializer=initializers.RandomNormal(mean=0.5,stddev=0.01), kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "                     bias_initializer=initializers.RandomNormal(mean=0.5,stddev=0.01), kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='sigmoid',\n",
        "                   kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer=initializers.RandomNormal(stddev=0.01),bias_initializer=initializers.RandomNormal(mean=0.5,stddev=0.01)))\n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the two images\n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    prediction = Dense(1,activation='sigmoid',bias_initializer=initializers.RandomNormal(mean=0.5,stddev=0.01))(L1_distance)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    \n",
        "    # return the model\n",
        "    return siamese_net"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1AbsD2wSwdT",
        "colab_type": "text"
      },
      "source": [
        "# VALIDATION AND TESTING FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u06nNngVBtl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def make_oneshot_task(N,s=\"val\"):\n",
        "\n",
        "        if s == \"val\":\n",
        "          X = X_valid\n",
        "        else:\n",
        "          X = X_train  \n",
        "\n",
        "        # Creating pairs of test image, support set for testing N way one shot learning\n",
        "        n_classes, n_examples, h, w = X.shape\n",
        "        indices = np.random.randint(0,n_examples,size=(N,))\n",
        "\n",
        "        categories = rng.choice(range(n_classes),size=(N,),replace=False)\n",
        "        true_category = categories[0]\n",
        "        ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
        "        test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
        "        support_set = X[categories,indices,:,:]\n",
        "        support_set[0,:,:] = X[true_category,ex2]\n",
        "        support_set = support_set.reshape(N, w, h,1)\n",
        "        targets = np.zeros((N,))\n",
        "        targets[0] = 1\n",
        "        targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "        pairs = [test_image,support_set]\n",
        "\n",
        "        return pairs, targets\n",
        "  \n",
        "  def test_oneshot(model,N,k,s=\"val\",verbose=0):\n",
        "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
        "        n_correct = 0\n",
        "        if verbose:\n",
        "            print(\"Evaluating model on {} random {} way one-shot learning tasks ... \".format(k,N))\n",
        "        for i in range(k):\n",
        "            inputs, targets = make_oneshot_task(N,s)\n",
        "            probs = model.predict(inputs)\n",
        "            if np.argmax(probs) == np.argmax(targets):\n",
        "                n_correct+=1\n",
        "        percent_correct = (100.0*n_correct / k)\n",
        "        if verbose:\n",
        "            print(\"Got an average of {}% {} way one-shot learning accuracy \".format(percent_correct,N))\n",
        "        return percent_correct\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84sgkviEVIUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "fd5a3c76-efc9-47de-9a1e-db19568705df"
      },
      "source": [
        "model = get_siamese_model((128,128,1))\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 4096)         68307776    input_7[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 4096)         0           sequential_3[0][0]               \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            4097        lambda_3[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 68,311,873\n",
            "Trainable params: 68,311,873\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im4mRyIzS5O0",
        "colab_type": "text"
      },
      "source": [
        "# COMPILING AND TRAINING THE MODEL "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOyiY6jvWgzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr = 0.00006)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8iExb8ab5Rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22bd5e08-d0fc-4753-93dc-d38910e91e32"
      },
      "source": [
        "# TRAINING THE MODEL\n",
        "\n",
        "evaluate_every = 10 # interval for evaluating on one-shot tasks\n",
        "loss_every = 10 # interval for printing loss (iterations)\n",
        "batch_size = 20\n",
        "n_iter = 5000\n",
        "N_way = 10 # how many classes for testing one-shot tasks>\n",
        "n_val = 25 # how many one-shot tasks to validate on?\n",
        "best = -1\n",
        "weights_path = 'Siamese.h5'\n",
        "weights_path2 = '/content/drive/My Drive/UNSW-Intern/weights/Siamese.h5'\n",
        "if os.path.exists(weights_path2):\n",
        "  model.load_weights(weights_path2)\n",
        "\n",
        "\n",
        "val_accs = []\n",
        "losses = []\n",
        "print(\"Starting training process!\")\n",
        "t_start = time.time()\n",
        "for i in range(1, n_iter):\n",
        "    (inputs,targets)=get_batch(X_train,batch_size,\"train\")\n",
        "    loss=model.train_on_batch(inputs,targets)\n",
        "    print(\"-------------\")\n",
        "    print(\"Loss after iteration {0}: {1} \\n\".format(i,loss)) \n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"Time for {0} iterations: {1}\".format(i, time.time()-t_start))\n",
        "        val_acc = test_oneshot(model,N_way,n_val,verbose=True)\n",
        "        val_accs.append(val_acc)  # Storing validation accuracies after every 10 iterations\n",
        "        if val_acc >= best:\n",
        "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best),\"therefore\",\"saving the weights to: {0}\".format(weights_path))\n",
        "            model.save_weights(weights_path2)\n",
        "            best=val_acc\n",
        "    \n",
        "    if i % loss_every == 0:\n",
        "        print(\"iteration {}, training loss: {:.2f},\".format(i,loss))\n",
        "        losses.append(loss)  # Storing losses after every 10 iterations\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "-------------\n",
            "Loss after iteration 3530: 0.16528202593326569 \n",
            "\n",
            "Time for 3530 iterations: 766.2289326190948\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 3530, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 3531: 0.20024017989635468 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3532: 0.19844719767570496 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3533: 0.2733577489852905 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3534: 0.13521143794059753 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3535: 0.16656580567359924 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3536: 0.16539549827575684 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3537: 0.14595583081245422 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3538: 0.19882115721702576 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3539: 0.22401709854602814 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3540: 0.1260468065738678 \n",
            "\n",
            "Time for 3540 iterations: 768.332070350647\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 3540, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 3541: 0.15330295264720917 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3542: 0.19808852672576904 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3543: 0.32015860080718994 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3544: 0.15213876962661743 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3545: 0.26183587312698364 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3546: 0.3498673439025879 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3547: 0.16607630252838135 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3548: 0.1993793547153473 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3549: 0.1949651539325714 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3550: 0.17072871327400208 \n",
            "\n",
            "Time for 3550 iterations: 770.4193952083588\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 3550, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 3551: 0.17807799577713013 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3552: 0.17220881581306458 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3553: 0.1417122632265091 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3554: 0.1830817312002182 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3555: 0.1541685163974762 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3556: 0.1443670243024826 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3557: 0.12128295749425888 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3558: 0.14632979035377502 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3559: 0.12559610605239868 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3560: 0.1772739738225937 \n",
            "\n",
            "Time for 3560 iterations: 772.5235466957092\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 3560, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 3561: 0.12670189142227173 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3562: 0.35057544708251953 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3563: 0.15402904152870178 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3564: 0.1618306189775467 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3565: 0.13445338606834412 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3566: 0.21326854825019836 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3567: 0.15670594573020935 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3568: 0.2296387255191803 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3569: 0.26190194487571716 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3570: 0.17468759417533875 \n",
            "\n",
            "Time for 3570 iterations: 774.6408541202545\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3570, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 3571: 0.21933773159980774 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3572: 0.20360422134399414 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3573: 0.1572524458169937 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3574: 0.16298940777778625 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3575: 0.16260352730751038 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3576: 0.3000357747077942 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3577: 0.2252349853515625 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3578: 0.18121567368507385 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3579: 0.2447349578142166 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3580: 0.1283128559589386 \n",
            "\n",
            "Time for 3580 iterations: 776.8206250667572\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3580, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 3581: 0.16177114844322205 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3582: 0.27999818325042725 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3583: 0.14843186736106873 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3584: 0.13109251856803894 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3585: 0.23083695769309998 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3586: 0.1943739652633667 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3587: 0.15121586620807648 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3588: 0.12220128625631332 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3589: 0.1465604454278946 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3590: 0.2643052935600281 \n",
            "\n",
            "Time for 3590 iterations: 778.99076795578\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 3590, training loss: 0.26,\n",
            "-------------\n",
            "Loss after iteration 3591: 0.10905800759792328 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3592: 0.20611710846424103 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3593: 0.18127423524856567 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3594: 0.1325393170118332 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3595: 0.18796685338020325 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3596: 0.18537622690200806 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3597: 0.3635033667087555 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3598: 0.12989717721939087 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3599: 0.1638057827949524 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3600: 0.20487138628959656 \n",
            "\n",
            "Time for 3600 iterations: 781.1344094276428\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3600, training loss: 0.20,\n",
            "-------------\n",
            "Loss after iteration 3601: 0.15032875537872314 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3602: 0.16667023301124573 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3603: 0.14519214630126953 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3604: 0.15352091193199158 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3605: 0.13780862092971802 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3606: 0.1250266581773758 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3607: 0.161650151014328 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3608: 0.16561630368232727 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3609: 0.18138161301612854 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3610: 0.19088046252727509 \n",
            "\n",
            "Time for 3610 iterations: 783.2799942493439\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 3610, training loss: 0.19,\n",
            "-------------\n",
            "Loss after iteration 3611: 0.24714645743370056 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3612: 0.19641058146953583 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3613: 0.29213953018188477 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3614: 0.19520238041877747 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3615: 0.21884503960609436 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3616: 0.1312633454799652 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3617: 0.17675527930259705 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3618: 0.15934941172599792 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3619: 0.16805589199066162 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3620: 0.13525709509849548 \n",
            "\n",
            "Time for 3620 iterations: 785.3867242336273\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 3620, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3621: 0.2212531566619873 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3622: 0.13546016812324524 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3623: 0.12186197936534882 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3624: 0.14468783140182495 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3625: 0.13594168424606323 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3626: 0.2580956518650055 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3627: 0.25232288241386414 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3628: 0.12655587494373322 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3629: 0.13935042917728424 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3630: 0.14473015069961548 \n",
            "\n",
            "Time for 3630 iterations: 787.512549161911\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 3630, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3631: 0.4137405753135681 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3632: 0.1454562246799469 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3633: 0.1444627344608307 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3634: 0.15743869543075562 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3635: 0.14827053248882294 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3636: 0.15219801664352417 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3637: 0.12013792991638184 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3638: 0.20469403266906738 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3639: 0.16124120354652405 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3640: 0.17958936095237732 \n",
            "\n",
            "Time for 3640 iterations: 789.6361193656921\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3640, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 3641: 0.14909888803958893 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3642: 0.14702153205871582 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3643: 0.11554676294326782 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3644: 0.3070521056652069 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3645: 0.1468355655670166 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3646: 0.14457571506500244 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3647: 0.12145991623401642 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3648: 0.17319151759147644 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3649: 0.1441943645477295 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3650: 0.19775182008743286 \n",
            "\n",
            "Time for 3650 iterations: 791.7747738361359\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3650, training loss: 0.20,\n",
            "-------------\n",
            "Loss after iteration 3651: 0.14344820380210876 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3652: 0.16734692454338074 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3653: 0.17244648933410645 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3654: 0.124477818608284 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3655: 0.12146522849798203 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3656: 0.14893776178359985 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3657: 0.12451396137475967 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3658: 0.1283561736345291 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3659: 0.14912977814674377 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3660: 0.18492400646209717 \n",
            "\n",
            "Time for 3660 iterations: 793.9020111560822\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3660, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 3661: 0.15165778994560242 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3662: 0.15216860175132751 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3663: 0.16878871619701385 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3664: 0.14168569445610046 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3665: 0.1961444616317749 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3666: 0.12379668653011322 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3667: 0.14257073402404785 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3668: 0.16849464178085327 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3669: 0.1574689745903015 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3670: 0.13319799304008484 \n",
            "\n",
            "Time for 3670 iterations: 796.0152249336243\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 3670, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 3671: 0.1336975395679474 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3672: 0.12182049453258514 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3673: 0.16104759275913239 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3674: 0.12065140902996063 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3675: 0.149809330701828 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3676: 0.12017995119094849 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3677: 0.14412617683410645 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3678: 0.14414489269256592 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3679: 0.14212116599082947 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3680: 0.1376451551914215 \n",
            "\n",
            "Time for 3680 iterations: 798.1131865978241\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 3680, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3681: 0.1366719752550125 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3682: 0.1397678554058075 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3683: 0.12894904613494873 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3684: 0.10960421711206436 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3685: 0.17208388447761536 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3686: 0.13892318308353424 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3687: 0.12741729617118835 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3688: 0.11021684110164642 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3689: 0.12303545325994492 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3690: 0.2164926528930664 \n",
            "\n",
            "Time for 3690 iterations: 800.2658505439758\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3690, training loss: 0.22,\n",
            "-------------\n",
            "Loss after iteration 3691: 0.17686788737773895 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3692: 0.15887372195720673 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3693: 0.15450146794319153 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3694: 0.11018909513950348 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3695: 0.3432125151157379 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3696: 0.13434016704559326 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3697: 0.18900400400161743 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3698: 0.16733747720718384 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3699: 0.1629020869731903 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3700: 0.15465565025806427 \n",
            "\n",
            "Time for 3700 iterations: 802.4226107597351\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 3700, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 3701: 0.15583303570747375 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3702: 0.15825378894805908 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3703: 0.1347743272781372 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3704: 0.29554325342178345 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3705: 0.19918277859687805 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3706: 0.14644120633602142 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3707: 0.2553679347038269 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3708: 0.15703342854976654 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3709: 0.11387379467487335 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3710: 0.1281602382659912 \n",
            "\n",
            "Time for 3710 iterations: 804.6886734962463\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3710, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 3711: 0.1475011706352234 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3712: 0.34155720472335815 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3713: 0.2730098366737366 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3714: 0.12453484535217285 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3715: 0.15328022837638855 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3716: 0.12237416207790375 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3717: 0.36467522382736206 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3718: 0.14828389883041382 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3719: 0.15874627232551575 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3720: 0.17522381246089935 \n",
            "\n",
            "Time for 3720 iterations: 806.7857418060303\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 3720, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 3721: 0.15056532621383667 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3722: 0.15033210813999176 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3723: 0.1267658770084381 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3724: 0.1238444447517395 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3725: 0.1396637260913849 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3726: 0.1474408060312271 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3727: 0.15843626856803894 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3728: 0.17399820685386658 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3729: 0.17915746569633484 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3730: 0.12788265943527222 \n",
            "\n",
            "Time for 3730 iterations: 808.9350783824921\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 3730, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 3731: 0.2002895176410675 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3732: 0.16741518676280975 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3733: 0.13219428062438965 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3734: 0.235150545835495 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3735: 0.23291635513305664 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3736: 0.1706346869468689 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3737: 0.12832313776016235 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3738: 0.13297846913337708 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3739: 0.14245453476905823 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3740: 0.13948708772659302 \n",
            "\n",
            "Time for 3740 iterations: 811.0623867511749\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 3740, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3741: 0.16497915983200073 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3742: 0.2918299436569214 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3743: 0.24452444911003113 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3744: 0.1812443733215332 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3745: 0.16772004961967468 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3746: 0.24262288212776184 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3747: 0.14445462822914124 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3748: 0.21973612904548645 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3749: 0.27827489376068115 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3750: 0.1644718050956726 \n",
            "\n",
            "Time for 3750 iterations: 813.1612367630005\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 3750, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 3751: 0.14508983492851257 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3752: 0.17908205091953278 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3753: 0.16108635067939758 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3754: 0.17072373628616333 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3755: 0.13985863327980042 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3756: 0.2153111696243286 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3757: 0.14693453907966614 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3758: 0.14755091071128845 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3759: 0.26649969816207886 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3760: 0.11659231036901474 \n",
            "\n",
            "Time for 3760 iterations: 815.2963852882385\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 3760, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 3761: 0.16563624143600464 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3762: 0.14406529068946838 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3763: 0.151557058095932 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3764: 0.16140705347061157 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3765: 0.15679915249347687 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3766: 0.14964699745178223 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3767: 0.14825809001922607 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3768: 0.1547214537858963 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3769: 0.14285080134868622 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3770: 0.18308302760124207 \n",
            "\n",
            "Time for 3770 iterations: 817.4091620445251\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 3770, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 3771: 0.15946638584136963 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3772: 0.22723746299743652 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3773: 0.15819622576236725 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3774: 0.1494525969028473 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3775: 0.2928016781806946 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3776: 0.17774638533592224 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3777: 0.13213342428207397 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3778: 0.3822370767593384 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3779: 0.26156002283096313 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3780: 0.1855258047580719 \n",
            "\n",
            "Time for 3780 iterations: 819.6077020168304\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 3780, training loss: 0.19,\n",
            "-------------\n",
            "Loss after iteration 3781: 0.27866578102111816 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3782: 0.21475282311439514 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3783: 0.1882166862487793 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3784: 0.21543189883232117 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3785: 0.3342035114765167 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3786: 0.17344391345977783 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3787: 0.21489331126213074 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3788: 0.2503131330013275 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3789: 0.1762252151966095 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3790: 0.17210987210273743 \n",
            "\n",
            "Time for 3790 iterations: 821.6995317935944\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 3790, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 3791: 0.2913237512111664 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3792: 0.15313144028186798 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3793: 0.17552253603935242 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3794: 0.16243389248847961 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3795: 0.16312864422798157 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3796: 0.12826161086559296 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3797: 0.14961764216423035 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3798: 0.12104891240596771 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3799: 0.1242971271276474 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3800: 0.12093693017959595 \n",
            "\n",
            "Time for 3800 iterations: 823.7935004234314\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3800, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 3801: 0.13476094603538513 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3802: 0.16046005487442017 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3803: 0.11351294815540314 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3804: 0.1273101270198822 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3805: 0.12168683111667633 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3806: 0.17000128328800201 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3807: 0.20806913077831268 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3808: 0.10726740211248398 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3809: 0.15323856472969055 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3810: 0.13994663953781128 \n",
            "\n",
            "Time for 3810 iterations: 825.9271841049194\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 3810, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3811: 0.16532352566719055 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3812: 0.25100386142730713 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3813: 0.2022363692522049 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3814: 0.29319122433662415 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3815: 0.14591696858406067 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3816: 0.12534326314926147 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3817: 0.13630592823028564 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3818: 0.2974943518638611 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3819: 0.17459604144096375 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3820: 0.14144879579544067 \n",
            "\n",
            "Time for 3820 iterations: 828.0484430789948\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3820, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3821: 0.15745872259140015 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3822: 0.1591741442680359 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3823: 0.2101336270570755 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3824: 0.19084316492080688 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3825: 0.20119419693946838 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3826: 0.14387676119804382 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3827: 0.20095214247703552 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3828: 0.12259472906589508 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3829: 0.13525423407554626 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3830: 0.18220415711402893 \n",
            "\n",
            "Time for 3830 iterations: 830.1463916301727\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 3830, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 3831: 0.20123422145843506 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3832: 0.15550380945205688 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3833: 0.28323429822921753 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3834: 0.122231625020504 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3835: 0.13548386096954346 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3836: 0.11770734935998917 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3837: 0.12913180887699127 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3838: 0.4089374542236328 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3839: 0.384212851524353 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3840: 0.2609930634498596 \n",
            "\n",
            "Time for 3840 iterations: 832.2625632286072\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3840, training loss: 0.26,\n",
            "-------------\n",
            "Loss after iteration 3841: 0.41712650656700134 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3842: 0.32381993532180786 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3843: 0.16687041521072388 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3844: 0.26091262698173523 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3845: 0.1442074179649353 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3846: 0.12775647640228271 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3847: 0.18059244751930237 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3848: 0.22314083576202393 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3849: 0.1901872307062149 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3850: 0.27550581097602844 \n",
            "\n",
            "Time for 3850 iterations: 834.3708252906799\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 3850, training loss: 0.28,\n",
            "-------------\n",
            "Loss after iteration 3851: 0.17238330841064453 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3852: 0.136012464761734 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3853: 0.6897007822990417 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3854: 0.15670034289360046 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3855: 0.15327733755111694 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3856: 0.2679065465927124 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3857: 0.2585591971874237 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3858: 0.2957344055175781 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3859: 0.2680741548538208 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3860: 0.21505241096019745 \n",
            "\n",
            "Time for 3860 iterations: 836.4798119068146\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3860, training loss: 0.22,\n",
            "-------------\n",
            "Loss after iteration 3861: 0.15720921754837036 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3862: 0.15572886168956757 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3863: 0.25433892011642456 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3864: 0.14201581478118896 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3865: 0.3627808392047882 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3866: 0.1376727670431137 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3867: 0.15976937115192413 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3868: 0.11966411769390106 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3869: 0.18505361676216125 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3870: 0.14449253678321838 \n",
            "\n",
            "Time for 3870 iterations: 838.6112644672394\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 3870, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3871: 0.16536127030849457 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3872: 0.1720622181892395 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3873: 0.15076178312301636 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3874: 0.2374841272830963 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3875: 0.12722794711589813 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3876: 0.18017518520355225 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3877: 0.1754598617553711 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3878: 0.18575544655323029 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3879: 0.20767445862293243 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3880: 0.16949912905693054 \n",
            "\n",
            "Time for 3880 iterations: 840.7731201648712\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3880, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 3881: 0.13749612867832184 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3882: 0.1342153251171112 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3883: 0.14663010835647583 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3884: 0.11794279515743256 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3885: 0.18148396909236908 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3886: 0.13705545663833618 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3887: 0.15120136737823486 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3888: 0.2261018306016922 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3889: 0.12745462357997894 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3890: 0.1273084133863449 \n",
            "\n",
            "Time for 3890 iterations: 842.885835647583\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 3890, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 3891: 0.140529602766037 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3892: 0.1808367669582367 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3893: 0.22316530346870422 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3894: 0.1534309834241867 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3895: 0.1908113807439804 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3896: 0.17698797583580017 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3897: 0.27324962615966797 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3898: 0.17255602777004242 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3899: 0.12224303185939789 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3900: 0.21458348631858826 \n",
            "\n",
            "Time for 3900 iterations: 845.0315766334534\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 3900, training loss: 0.21,\n",
            "-------------\n",
            "Loss after iteration 3901: 0.18931317329406738 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3902: 0.25247544050216675 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3903: 0.23368516564369202 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3904: 0.2865006923675537 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3905: 0.15091031789779663 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3906: 0.16112351417541504 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3907: 0.18662677705287933 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3908: 0.16739672422409058 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3909: 0.12869909405708313 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3910: 0.16998782753944397 \n",
            "\n",
            "Time for 3910 iterations: 847.1595902442932\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3910, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 3911: 0.11777223646640778 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3912: 0.11490608751773834 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3913: 0.15013377368450165 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3914: 0.14614740014076233 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3915: 0.1980232447385788 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3916: 0.15630628168582916 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3917: 0.20528724789619446 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3918: 0.1837797313928604 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3919: 0.1756475865840912 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3920: 0.13525980710983276 \n",
            "\n",
            "Time for 3920 iterations: 849.3134384155273\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 3920, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3921: 0.1839987337589264 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3922: 0.2615492641925812 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3923: 0.14306780695915222 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3924: 0.17745700478553772 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3925: 0.25189486145973206 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3926: 0.15640482306480408 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3927: 0.15121954679489136 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3928: 0.28729307651519775 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3929: 0.15038585662841797 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3930: 0.14205655455589294 \n",
            "\n",
            "Time for 3930 iterations: 851.480144739151\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 3930, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3931: 0.1737673282623291 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3932: 0.17744234204292297 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3933: 0.17058426141738892 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3934: 0.1335882991552353 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3935: 0.13106149435043335 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3936: 0.2034921646118164 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3937: 0.16864170134067535 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3938: 0.20715856552124023 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3939: 0.2113879919052124 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3940: 0.138020321726799 \n",
            "\n",
            "Time for 3940 iterations: 853.7620584964752\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 3940, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3941: 0.11558376252651215 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3942: 0.15256789326667786 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3943: 0.18513232469558716 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3944: 0.14640024304389954 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3945: 0.2728240191936493 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3946: 0.16533179581165314 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3947: 0.18177536129951477 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3948: 0.16378958523273468 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3949: 0.14469583332538605 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3950: 0.13300591707229614 \n",
            "\n",
            "Time for 3950 iterations: 855.8501465320587\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 3950, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 3951: 0.1794012188911438 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3952: 0.1987963616847992 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3953: 0.14131884276866913 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3954: 0.12904608249664307 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3955: 0.2474551945924759 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3956: 0.12922963500022888 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3957: 0.17458833754062653 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3958: 0.24790608882904053 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3959: 0.17558369040489197 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3960: 0.1653544008731842 \n",
            "\n",
            "Time for 3960 iterations: 858.0213091373444\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 3960, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 3961: 0.16354745626449585 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3962: 0.13441863656044006 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3963: 0.19035938382148743 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3964: 0.32256054878234863 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3965: 0.11088277399539948 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3966: 0.20629051327705383 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3967: 0.11649539321660995 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3968: 0.13019338250160217 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3969: 0.216688871383667 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3970: 0.13488394021987915 \n",
            "\n",
            "Time for 3970 iterations: 860.1148252487183\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3970, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 3971: 0.14869016408920288 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3972: 0.15799757838249207 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3973: 0.15331479907035828 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3974: 0.16167613863945007 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3975: 0.1901075541973114 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3976: 0.17383599281311035 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3977: 0.29261836409568787 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3978: 0.17548392713069916 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3979: 0.14485575258731842 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3980: 0.1287050098180771 \n",
            "\n",
            "Time for 3980 iterations: 862.2851827144623\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 3980, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 3981: 0.14927834272384644 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3982: 0.23544800281524658 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3983: 0.14603209495544434 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3984: 0.14336536824703217 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3985: 0.13801220059394836 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3986: 0.16638727486133575 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3987: 0.2696935534477234 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3988: 0.1190633550286293 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3989: 0.1259557604789734 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3990: 0.13741829991340637 \n",
            "\n",
            "Time for 3990 iterations: 864.4798855781555\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 3990, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 3991: 0.12304836511611938 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3992: 0.14537875354290009 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3993: 0.18233241140842438 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3994: 0.14691996574401855 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3995: 0.17072094976902008 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3996: 0.2754287123680115 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3997: 0.14360281825065613 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3998: 0.15878203511238098 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 3999: 0.11762557178735733 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4000: 0.38261088728904724 \n",
            "\n",
            "Time for 4000 iterations: 866.6349008083344\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4000, training loss: 0.38,\n",
            "-------------\n",
            "Loss after iteration 4001: 0.16752296686172485 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4002: 0.12480010837316513 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4003: 0.15171906352043152 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4004: 0.14822185039520264 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4005: 0.12085224688053131 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4006: 0.1472424566745758 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4007: 0.1625944972038269 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4008: 0.1481732428073883 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4009: 0.12902040779590607 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4010: 0.13656894862651825 \n",
            "\n",
            "Time for 4010 iterations: 868.7426781654358\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4010, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4011: 0.2651308476924896 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4012: 0.2119065523147583 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4013: 0.13788393139839172 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4014: 0.15570908784866333 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4015: 0.14208701252937317 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4016: 0.17559947073459625 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4017: 0.13496939837932587 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4018: 0.3383225202560425 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4019: 0.1879623532295227 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4020: 0.15553812682628632 \n",
            "\n",
            "Time for 4020 iterations: 870.8796482086182\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4020, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4021: 0.13941021263599396 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4022: 0.15977710485458374 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4023: 0.12074458599090576 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4024: 0.2444297969341278 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4025: 0.17981798946857452 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4026: 0.16466306149959564 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4027: 0.185583233833313 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4028: 0.1223302036523819 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4029: 0.15851493179798126 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4030: 0.13225913047790527 \n",
            "\n",
            "Time for 4030 iterations: 873.0621018409729\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 4030, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4031: 0.12910524010658264 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4032: 0.14008750021457672 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4033: 0.11990286409854889 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4034: 0.1251567006111145 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4035: 0.15595565736293793 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4036: 0.13593748211860657 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4037: 0.16043949127197266 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4038: 0.36337462067604065 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4039: 0.22011587023735046 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4040: 0.13850268721580505 \n",
            "\n",
            "Time for 4040 iterations: 875.1958267688751\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 24.0% 10 way one-shot learning accuracy \n",
            "iteration 4040, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4041: 0.27322638034820557 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4042: 0.17246407270431519 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4043: 0.15697705745697021 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4044: 0.1757773607969284 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4045: 0.11311258375644684 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4046: 0.20422843098640442 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4047: 0.18997910618782043 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4048: 0.12329224497079849 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4049: 0.11828222125768661 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4050: 0.11497166007757187 \n",
            "\n",
            "Time for 4050 iterations: 877.3093376159668\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4050, training loss: 0.11,\n",
            "-------------\n",
            "Loss after iteration 4051: 0.1630517840385437 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4052: 0.12859472632408142 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4053: 0.13905201852321625 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4054: 0.18793441355228424 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4055: 0.19005689024925232 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4056: 0.18066653609275818 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4057: 0.14892151951789856 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4058: 0.1655385047197342 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4059: 0.1292555034160614 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4060: 0.15023091435432434 \n",
            "\n",
            "Time for 4060 iterations: 879.4533643722534\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4060, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4061: 0.38418152928352356 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4062: 0.12319197505712509 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4063: 0.12605801224708557 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4064: 0.2586154341697693 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4065: 0.1740259826183319 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4066: 0.222796231508255 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4067: 0.1661820411682129 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4068: 0.1424022912979126 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4069: 0.14906267821788788 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4070: 0.14258654415607452 \n",
            "\n",
            "Time for 4070 iterations: 881.5622253417969\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4070, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4071: 0.15345314145088196 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4072: 0.21823973953723907 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4073: 0.16292229294776917 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4074: 0.20867326855659485 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4075: 0.16876131296157837 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4076: 0.14880208671092987 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4077: 0.16070100665092468 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4078: 0.27520525455474854 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4079: 0.12496452033519745 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4080: 0.1509925127029419 \n",
            "\n",
            "Time for 4080 iterations: 883.6916401386261\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4080, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4081: 0.2050161063671112 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4082: 0.20666071772575378 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4083: 0.15597102046012878 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4084: 0.1652931123971939 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4085: 0.17843356728553772 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4086: 0.12230755388736725 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4087: 0.11246834695339203 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4088: 0.1691829264163971 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4089: 0.22311273217201233 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4090: 0.20420756936073303 \n",
            "\n",
            "Time for 4090 iterations: 885.865663766861\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 4090, training loss: 0.20,\n",
            "-------------\n",
            "Loss after iteration 4091: 0.15468129515647888 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4092: 0.1456265151500702 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4093: 0.15890207886695862 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4094: 0.18405722081661224 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4095: 0.12325344234704971 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4096: 0.12924924492835999 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4097: 0.1242954358458519 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4098: 0.15478426218032837 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4099: 0.11441829055547714 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4100: 0.12912729382514954 \n",
            "\n",
            "Time for 4100 iterations: 887.9625627994537\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4100, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4101: 0.15825507044792175 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4102: 0.15908822417259216 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4103: 0.12359833717346191 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4104: 0.15393686294555664 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4105: 0.14681802690029144 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4106: 0.1209048181772232 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4107: 0.11820027977228165 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4108: 0.20545384287834167 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4109: 0.12433655560016632 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4110: 0.18711793422698975 \n",
            "\n",
            "Time for 4110 iterations: 890.0514557361603\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4110, training loss: 0.19,\n",
            "-------------\n",
            "Loss after iteration 4111: 0.15331843495368958 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4112: 0.15959861874580383 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4113: 0.15938645601272583 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4114: 0.15771231055259705 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4115: 0.17225264012813568 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4116: 0.14264580607414246 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4117: 0.1366618573665619 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4118: 0.11900019645690918 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4119: 0.13972768187522888 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4120: 0.18123729526996613 \n",
            "\n",
            "Time for 4120 iterations: 892.1780562400818\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4120, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 4121: 0.12263349443674088 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4122: 0.14880873262882233 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4123: 0.14770764112472534 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4124: 0.11989255249500275 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4125: 0.2963322401046753 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4126: 0.12193436920642853 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4127: 0.17154261469841003 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4128: 0.14245638251304626 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4129: 0.1347125768661499 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4130: 0.15333323180675507 \n",
            "\n",
            "Time for 4130 iterations: 894.356767654419\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4130, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4131: 0.13621509075164795 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4132: 0.1763773262500763 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4133: 0.12202811241149902 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4134: 0.153066486120224 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4135: 0.1575157195329666 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4136: 0.14610561728477478 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4137: 0.12864437699317932 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4138: 0.15072917938232422 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4139: 0.20893573760986328 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4140: 0.20962873101234436 \n",
            "\n",
            "Time for 4140 iterations: 896.4611122608185\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 32.0% 10 way one-shot learning accuracy \n",
            "Current best: 32.0, previous best: 32.0 therefore saving the weights to: Siamese.h5\n",
            "iteration 4140, training loss: 0.21,\n",
            "-------------\n",
            "Loss after iteration 4141: 0.11603720486164093 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4142: 0.11481660604476929 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4143: 0.13190145790576935 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4144: 0.11866404116153717 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4145: 0.1298445463180542 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4146: 0.11989642679691315 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4147: 0.1135122999548912 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4148: 0.35142067074775696 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4149: 0.15177258849143982 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4150: 0.2386239469051361 \n",
            "\n",
            "Time for 4150 iterations: 900.0900642871857\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4150, training loss: 0.24,\n",
            "-------------\n",
            "Loss after iteration 4151: 0.24079835414886475 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4152: 0.17623257637023926 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4153: 0.15108591318130493 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4154: 0.20559397339820862 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4155: 0.1310802847146988 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4156: 0.14469856023788452 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4157: 0.11703038215637207 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4158: 0.16426509618759155 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4159: 0.2394196093082428 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4160: 0.16178229451179504 \n",
            "\n",
            "Time for 4160 iterations: 902.4822337627411\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 4160, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4161: 0.15510624647140503 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4162: 0.12089322507381439 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4163: 0.2193281650543213 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4164: 0.1496511846780777 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4165: 0.14373648166656494 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4166: 0.14355434477329254 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4167: 0.13469842076301575 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4168: 0.2336800992488861 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4169: 0.16715458035469055 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4170: 0.16851219534873962 \n",
            "\n",
            "Time for 4170 iterations: 904.627569437027\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 4170, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 4171: 0.13822561502456665 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4172: 0.17465493083000183 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4173: 0.1471981406211853 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4174: 0.1574951857328415 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4175: 0.19471333920955658 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4176: 0.12851984798908234 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4177: 0.1535331904888153 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4178: 0.1406249850988388 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4179: 0.11671333014965057 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4180: 0.11522768437862396 \n",
            "\n",
            "Time for 4180 iterations: 906.8025722503662\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4180, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 4181: 0.1623440384864807 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4182: 0.13108250498771667 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4183: 0.19232599437236786 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4184: 0.15110792219638824 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4185: 0.13580186665058136 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4186: 0.13304555416107178 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4187: 0.15948396921157837 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4188: 0.1825455129146576 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4189: 0.11204256862401962 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4190: 0.2006755769252777 \n",
            "\n",
            "Time for 4190 iterations: 908.9871296882629\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4190, training loss: 0.20,\n",
            "-------------\n",
            "Loss after iteration 4191: 0.11473770439624786 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4192: 0.15985792875289917 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4193: 0.19904202222824097 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4194: 0.14100351929664612 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4195: 0.11371685564517975 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4196: 0.1295085996389389 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4197: 0.10735119879245758 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4198: 0.1681629866361618 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4199: 0.18856534361839294 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4200: 0.13834528625011444 \n",
            "\n",
            "Time for 4200 iterations: 911.4337797164917\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4200, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4201: 0.12463845312595367 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4202: 0.1151541918516159 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4203: 0.24283389747142792 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4204: 0.1100149005651474 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4205: 0.1946427822113037 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4206: 0.1722361296415329 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4207: 0.155453622341156 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4208: 0.1290474534034729 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4209: 0.20651981234550476 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4210: 0.1593279242515564 \n",
            "\n",
            "Time for 4210 iterations: 913.5845754146576\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4210, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4211: 0.2240438014268875 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4212: 0.1534459888935089 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4213: 0.11567248404026031 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4214: 0.23878809809684753 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4215: 0.13466641306877136 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4216: 0.12981732189655304 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4217: 0.15567216277122498 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4218: 0.1391524374485016 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4219: 0.13271382451057434 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4220: 0.1550273597240448 \n",
            "\n",
            "Time for 4220 iterations: 915.7414200305939\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4220, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4221: 0.18294444680213928 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4222: 0.28322866559028625 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4223: 0.4095032215118408 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4224: 0.17170235514640808 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4225: 0.12920136749744415 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4226: 0.15237665176391602 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4227: 0.15197309851646423 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4228: 0.1298602819442749 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4229: 0.2159719467163086 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4230: 0.11807321012020111 \n",
            "\n",
            "Time for 4230 iterations: 917.8739693164825\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4230, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 4231: 0.12286567687988281 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4232: 0.142769455909729 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4233: 0.1674334704875946 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4234: 0.14689725637435913 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4235: 0.15956762433052063 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4236: 0.11505824327468872 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4237: 0.11291395127773285 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4238: 0.187529057264328 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4239: 0.13011355698108673 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4240: 0.13935449719429016 \n",
            "\n",
            "Time for 4240 iterations: 919.9825177192688\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4240, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4241: 0.1344296634197235 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4242: 0.16238179802894592 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4243: 0.143687441945076 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4244: 0.1548948436975479 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4245: 0.1615992784500122 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4246: 0.12250735610723495 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4247: 0.10956497490406036 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4248: 0.12075203657150269 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4249: 0.19051089882850647 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4250: 0.23683473467826843 \n",
            "\n",
            "Time for 4250 iterations: 922.0911180973053\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4250, training loss: 0.24,\n",
            "-------------\n",
            "Loss after iteration 4251: 0.11560533940792084 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4252: 0.14009416103363037 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4253: 0.21377572417259216 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4254: 0.13031478226184845 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4255: 0.16955186426639557 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4256: 0.20988988876342773 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4257: 0.2042936533689499 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4258: 0.13050459325313568 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4259: 0.17656800150871277 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4260: 0.26466554403305054 \n",
            "\n",
            "Time for 4260 iterations: 924.2094223499298\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 4260, training loss: 0.26,\n",
            "-------------\n",
            "Loss after iteration 4261: 0.12443379312753677 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4262: 0.12748011946678162 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4263: 0.16294534504413605 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4264: 0.12216339260339737 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4265: 0.2751409411430359 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4266: 0.1306343674659729 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4267: 0.16813069581985474 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4268: 0.1531468629837036 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4269: 0.15904176235198975 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4270: 0.10796822607517242 \n",
            "\n",
            "Time for 4270 iterations: 926.4513330459595\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 4270, training loss: 0.11,\n",
            "-------------\n",
            "Loss after iteration 4271: 0.12555299699306488 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4272: 0.11502121388912201 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4273: 0.11096370220184326 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4274: 0.13014043867588043 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4275: 0.1483907252550125 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4276: 0.19494764506816864 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4277: 0.20786383748054504 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4278: 0.1354139745235443 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4279: 0.1284046471118927 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4280: 0.2019137144088745 \n",
            "\n",
            "Time for 4280 iterations: 928.6051008701324\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4280, training loss: 0.20,\n",
            "-------------\n",
            "Loss after iteration 4281: 0.1287587732076645 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4282: 0.12568724155426025 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4283: 0.11244885623455048 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4284: 0.12160700559616089 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4285: 0.16112461686134338 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4286: 0.1234530359506607 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4287: 0.1663876473903656 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4288: 0.13563746213912964 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4289: 0.21682414412498474 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4290: 0.158594012260437 \n",
            "\n",
            "Time for 4290 iterations: 930.7653195858002\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 24.0% 10 way one-shot learning accuracy \n",
            "iteration 4290, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4291: 0.10993210971355438 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4292: 0.10719941556453705 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4293: 0.11152134090662003 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4294: 0.16164875030517578 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4295: 0.23109276592731476 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4296: 0.1954755187034607 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4297: 0.24599580466747284 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4298: 0.12291894853115082 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4299: 0.19648127257823944 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4300: 0.2596319317817688 \n",
            "\n",
            "Time for 4300 iterations: 932.9434552192688\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 24.0% 10 way one-shot learning accuracy \n",
            "iteration 4300, training loss: 0.26,\n",
            "-------------\n",
            "Loss after iteration 4301: 0.19180084764957428 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4302: 0.1333114206790924 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4303: 0.11741182953119278 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4304: 0.18629193305969238 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4305: 0.11647043377161026 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4306: 0.3196646273136139 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4307: 0.13829559087753296 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4308: 0.15942449867725372 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4309: 0.15854325890541077 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4310: 0.18096862733364105 \n",
            "\n",
            "Time for 4310 iterations: 935.079380273819\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4310, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 4311: 0.17607426643371582 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4312: 0.25348961353302 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4313: 0.17607475817203522 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4314: 0.12117423117160797 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4315: 0.12406835705041885 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4316: 0.11170826852321625 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4317: 0.12723655998706818 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4318: 0.11069734394550323 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4319: 0.1573418825864792 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4320: 0.35372108221054077 \n",
            "\n",
            "Time for 4320 iterations: 937.2289912700653\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4320, training loss: 0.35,\n",
            "-------------\n",
            "Loss after iteration 4321: 0.1772754043340683 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4322: 0.15501601994037628 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4323: 0.17597994208335876 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4324: 0.19464142620563507 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4325: 0.16342493891716003 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4326: 0.1319076120853424 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4327: 0.12331610918045044 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4328: 0.18921522796154022 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4329: 0.1357017159461975 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4330: 0.14688435196876526 \n",
            "\n",
            "Time for 4330 iterations: 939.3327646255493\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4330, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4331: 0.13299617171287537 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4332: 0.1702592670917511 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4333: 0.2192101925611496 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4334: 0.1289307326078415 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4335: 0.1267966628074646 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4336: 0.3518660068511963 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4337: 0.1226106658577919 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4338: 0.15390613675117493 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4339: 0.13414236903190613 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4340: 0.16704106330871582 \n",
            "\n",
            "Time for 4340 iterations: 941.4448812007904\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4340, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 4341: 0.17191877961158752 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4342: 0.1448589712381363 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4343: 0.1489999145269394 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4344: 0.16159310936927795 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4345: 0.12060737609863281 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4346: 0.13424427807331085 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4347: 0.18335659801959991 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4348: 0.11061165481805801 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4349: 0.14129123091697693 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4350: 0.1517357975244522 \n",
            "\n",
            "Time for 4350 iterations: 943.5701141357422\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4350, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4351: 0.15306515991687775 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4352: 0.10765566676855087 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4353: 0.12509161233901978 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4354: 0.10702906548976898 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4355: 0.12897086143493652 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4356: 0.1094285100698471 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4357: 0.2414034605026245 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4358: 0.11650925874710083 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4359: 0.1411440521478653 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4360: 0.13846030831336975 \n",
            "\n",
            "Time for 4360 iterations: 945.7252540588379\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 4360, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4361: 0.10594820976257324 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4362: 0.1356240212917328 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4363: 0.19502213597297668 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4364: 0.1327175498008728 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4365: 0.14931565523147583 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4366: 0.14908632636070251 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4367: 0.11835843324661255 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4368: 0.24669793248176575 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4369: 0.17791029810905457 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4370: 0.20370808243751526 \n",
            "\n",
            "Time for 4370 iterations: 947.8774125576019\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4370, training loss: 0.20,\n",
            "-------------\n",
            "Loss after iteration 4371: 0.16965481638908386 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4372: 0.15702956914901733 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4373: 0.15470409393310547 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4374: 0.2464691400527954 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4375: 0.15872597694396973 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4376: 0.18150712549686432 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4377: 0.2752130329608917 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4378: 0.14875656366348267 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4379: 0.23660878837108612 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4380: 0.17890065908432007 \n",
            "\n",
            "Time for 4380 iterations: 950.0015497207642\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4380, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 4381: 0.16857877373695374 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4382: 0.11504937708377838 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4383: 0.22223849594593048 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4384: 0.15024593472480774 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4385: 0.17448663711547852 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4386: 0.16259919106960297 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4387: 0.1564129889011383 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4388: 0.18807804584503174 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4389: 0.14246699213981628 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4390: 0.16182038187980652 \n",
            "\n",
            "Time for 4390 iterations: 952.310348033905\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4390, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4391: 0.1228557676076889 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4392: 0.14998477697372437 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4393: 0.1684306412935257 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4394: 0.2886224389076233 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4395: 0.35004115104675293 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4396: 0.12448029220104218 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4397: 0.11776654422283173 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4398: 0.214903324842453 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4399: 0.11944717168807983 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4400: 0.16008588671684265 \n",
            "\n",
            "Time for 4400 iterations: 954.4190979003906\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4400, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4401: 0.15136878192424774 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4402: 0.12861478328704834 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4403: 0.14546960592269897 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4404: 0.14350515604019165 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4405: 0.11727099120616913 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4406: 0.25682955980300903 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4407: 0.12342759221792221 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4408: 0.1565103530883789 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4409: 0.1500549614429474 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4410: 0.1177893653512001 \n",
            "\n",
            "Time for 4410 iterations: 956.5474030971527\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4410, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 4411: 0.1354224979877472 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4412: 0.18451936542987823 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4413: 0.15517795085906982 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4414: 0.22378435730934143 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4415: 0.15490049123764038 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4416: 0.12047262489795685 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4417: 0.15530258417129517 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4418: 0.12745550274848938 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4419: 0.19360804557800293 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4420: 0.14911288022994995 \n",
            "\n",
            "Time for 4420 iterations: 958.7556817531586\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4420, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4421: 0.21571698784828186 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4422: 0.2410796582698822 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4423: 0.17549562454223633 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4424: 0.13275748491287231 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4425: 0.1148785799741745 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4426: 0.12475518137216568 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4427: 0.11219178140163422 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4428: 0.11074082553386688 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4429: 0.13754110038280487 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4430: 0.16007179021835327 \n",
            "\n",
            "Time for 4430 iterations: 960.8914093971252\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 4430, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4431: 0.14696212112903595 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4432: 0.1841849684715271 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4433: 0.13256224989891052 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4434: 0.11913560330867767 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4435: 0.15087638795375824 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4436: 0.14818397164344788 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4437: 0.1152849793434143 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4438: 0.10539426654577255 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4439: 0.11829520761966705 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4440: 0.1843479722738266 \n",
            "\n",
            "Time for 4440 iterations: 963.0299799442291\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4440, training loss: 0.18,\n",
            "-------------\n",
            "Loss after iteration 4441: 0.14901268482208252 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4442: 0.1304480880498886 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4443: 0.16042494773864746 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4444: 0.1296490877866745 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4445: 0.1463978886604309 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4446: 0.15945440530776978 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4447: 0.13320782780647278 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4448: 0.1420353651046753 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4449: 0.14031660556793213 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4450: 0.23381133377552032 \n",
            "\n",
            "Time for 4450 iterations: 965.1449553966522\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4450, training loss: 0.23,\n",
            "-------------\n",
            "Loss after iteration 4451: 0.13580965995788574 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4452: 0.146543949842453 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4453: 0.12760889530181885 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4454: 0.1759168803691864 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4455: 0.14116793870925903 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4456: 0.15220710635185242 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4457: 0.12123415619134903 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4458: 0.18020835518836975 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4459: 0.21949633955955505 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4460: 0.13580584526062012 \n",
            "\n",
            "Time for 4460 iterations: 967.2795503139496\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4460, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4461: 0.2289634644985199 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4462: 0.13249291479587555 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4463: 0.12072521448135376 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4464: 0.1579490453004837 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4465: 0.10740698873996735 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4466: 0.11514447629451752 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4467: 0.24017970263957977 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4468: 0.14749795198440552 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4469: 0.1431100070476532 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4470: 0.132632777094841 \n",
            "\n",
            "Time for 4470 iterations: 969.4182267189026\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4470, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4471: 0.1347140520811081 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4472: 0.1330578327178955 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4473: 0.13799872994422913 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4474: 0.13348329067230225 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4475: 0.19017302989959717 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4476: 0.15004625916481018 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4477: 0.14869149029254913 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4478: 0.15157178044319153 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4479: 0.24135537445545197 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4480: 0.2745870351791382 \n",
            "\n",
            "Time for 4480 iterations: 971.5782535076141\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 4480, training loss: 0.27,\n",
            "-------------\n",
            "Loss after iteration 4481: 0.2786852717399597 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4482: 0.12874823808670044 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4483: 0.16630956530570984 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4484: 0.1798752248287201 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4485: 0.1271742582321167 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4486: 0.11954443156719208 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4487: 0.10972459614276886 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4488: 0.16081275045871735 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4489: 0.12673410773277283 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4490: 0.15758121013641357 \n",
            "\n",
            "Time for 4490 iterations: 973.6752655506134\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4490, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4491: 0.11017560958862305 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4492: 0.2172570526599884 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4493: 0.15298344194889069 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4494: 0.1369609236717224 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4495: 0.16035515069961548 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4496: 0.1554383635520935 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4497: 0.2767908573150635 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4498: 0.19008079171180725 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4499: 0.13188908994197845 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4500: 0.16137906908988953 \n",
            "\n",
            "Time for 4500 iterations: 975.8728201389313\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 24.0% 10 way one-shot learning accuracy \n",
            "iteration 4500, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4501: 0.11814012378454208 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4502: 0.1389048844575882 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4503: 0.1703302264213562 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4504: 0.14178985357284546 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4505: 0.13753265142440796 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4506: 0.1432473510503769 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4507: 0.10368324816226959 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4508: 0.1272267997264862 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4509: 0.10931267589330673 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4510: 0.10439850389957428 \n",
            "\n",
            "Time for 4510 iterations: 978.0384812355042\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 24.0% 10 way one-shot learning accuracy \n",
            "iteration 4510, training loss: 0.10,\n",
            "-------------\n",
            "Loss after iteration 4511: 0.21552720665931702 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4512: 0.13403640687465668 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4513: 0.1257585734128952 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4514: 0.138553649187088 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4515: 0.2371671199798584 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4516: 0.15356184542179108 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4517: 0.1224309429526329 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4518: 0.116899274289608 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4519: 0.10613001883029938 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4520: 0.1248486265540123 \n",
            "\n",
            "Time for 4520 iterations: 980.2064681053162\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4520, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 4521: 0.16608190536499023 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4522: 0.1120869368314743 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4523: 0.11449678242206573 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4524: 0.17857089638710022 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4525: 0.18757231533527374 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4526: 0.10888590663671494 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4527: 0.16477425396442413 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4528: 0.19997791945934296 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4529: 0.123741015791893 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4530: 0.20366120338439941 \n",
            "\n",
            "Time for 4530 iterations: 982.3384802341461\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4530, training loss: 0.20,\n",
            "-------------\n",
            "Loss after iteration 4531: 0.16159513592720032 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4532: 0.1987418830394745 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4533: 0.1374405473470688 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4534: 0.12540407478809357 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4535: 0.2947632074356079 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4536: 0.1465281993150711 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4537: 0.2093801200389862 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4538: 0.1730910837650299 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4539: 0.13720551133155823 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4540: 0.1310034841299057 \n",
            "\n",
            "Time for 4540 iterations: 984.4353005886078\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 4540, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4541: 0.1753365397453308 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4542: 0.14678362011909485 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4543: 0.12080739438533783 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4544: 0.18703311681747437 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4545: 0.17296817898750305 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4546: 0.15049472451210022 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4547: 0.10663558542728424 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4548: 0.12766587734222412 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4549: 0.18639177083969116 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4550: 0.12199769914150238 \n",
            "\n",
            "Time for 4550 iterations: 986.5507895946503\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4550, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 4551: 0.12616685032844543 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4552: 0.1216944009065628 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4553: 0.13065573573112488 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4554: 0.14170339703559875 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4555: 0.11291749775409698 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4556: 0.17176508903503418 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4557: 0.12344696372747421 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4558: 0.15708962082862854 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4559: 0.21633374691009521 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4560: 0.1300768256187439 \n",
            "\n",
            "Time for 4560 iterations: 988.7264723777771\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 4560, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4561: 0.1375199854373932 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4562: 0.14854109287261963 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4563: 0.11425046622753143 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4564: 0.10255193710327148 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4565: 0.12875613570213318 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4566: 0.1820649802684784 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4567: 0.1264869123697281 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4568: 0.16116014122962952 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4569: 0.14724552631378174 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4570: 0.2180362492799759 \n",
            "\n",
            "Time for 4570 iterations: 990.9187459945679\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4570, training loss: 0.22,\n",
            "-------------\n",
            "Loss after iteration 4571: 0.14514686167240143 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4572: 0.1215752586722374 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4573: 0.10687649250030518 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4574: 0.23890531063079834 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4575: 0.16012248396873474 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4576: 0.11463482677936554 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4577: 0.14463844895362854 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4578: 0.1247997134923935 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4579: 0.12122297286987305 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4580: 0.13318964838981628 \n",
            "\n",
            "Time for 4580 iterations: 993.0777480602264\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4580, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4581: 0.18999594449996948 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4582: 0.2784377336502075 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4583: 0.1975218653678894 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4584: 0.12455461174249649 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4585: 0.1369803547859192 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4586: 0.14323750138282776 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4587: 0.13041669130325317 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4588: 0.13306832313537598 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4589: 0.25046616792678833 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4590: 0.16020263731479645 \n",
            "\n",
            "Time for 4590 iterations: 995.2280540466309\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4590, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4591: 0.11799764633178711 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4592: 0.11669732630252838 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4593: 0.21151182055473328 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4594: 0.26715248823165894 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4595: 0.17087584733963013 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4596: 0.12096796929836273 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4597: 0.11938291788101196 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4598: 0.11364339292049408 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4599: 0.15515455603599548 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4600: 0.191834956407547 \n",
            "\n",
            "Time for 4600 iterations: 997.3680386543274\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4600, training loss: 0.19,\n",
            "-------------\n",
            "Loss after iteration 4601: 0.13442805409431458 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4602: 0.1582874059677124 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4603: 0.15760502219200134 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4604: 0.12961135804653168 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4605: 0.11615747213363647 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4606: 0.11260856688022614 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4607: 0.16389060020446777 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4608: 0.1695379614830017 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4609: 0.11387859284877777 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4610: 0.10515929758548737 \n",
            "\n",
            "Time for 4610 iterations: 999.7194790840149\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4610, training loss: 0.11,\n",
            "-------------\n",
            "Loss after iteration 4611: 0.21519610285758972 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4612: 0.16124066710472107 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4613: 0.13623058795928955 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4614: 0.16386228799819946 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4615: 0.16510899364948273 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4616: 0.13050054013729095 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4617: 0.17311346530914307 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4618: 0.11177091300487518 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4619: 0.15080589056015015 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4620: 0.1406635195016861 \n",
            "\n",
            "Time for 4620 iterations: 1001.865266084671\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4620, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4621: 0.14958597719669342 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4622: 0.10807106643915176 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4623: 0.1103033795952797 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4624: 0.12464939057826996 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4625: 0.14545080065727234 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4626: 0.11679697036743164 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4627: 0.17276068031787872 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4628: 0.14937181770801544 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4629: 0.12040199339389801 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4630: 0.2080313265323639 \n",
            "\n",
            "Time for 4630 iterations: 1004.010235786438\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4630, training loss: 0.21,\n",
            "-------------\n",
            "Loss after iteration 4631: 0.1112421527504921 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4632: 0.16409990191459656 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4633: 0.1549513339996338 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4634: 0.1523367166519165 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4635: 0.1153654009103775 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4636: 0.1214570552110672 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4637: 0.1430225670337677 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4638: 0.13587161898612976 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4639: 0.13343532383441925 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4640: 0.12124262005090714 \n",
            "\n",
            "Time for 4640 iterations: 1006.1229569911957\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4640, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 4641: 0.24030761420726776 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4642: 0.13674655556678772 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4643: 0.15288475155830383 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4644: 0.2100171595811844 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4645: 0.12154167890548706 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4646: 0.161912739276886 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4647: 0.11600174754858017 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4648: 0.1380995512008667 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4649: 0.11883920431137085 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4650: 0.15076088905334473 \n",
            "\n",
            "Time for 4650 iterations: 1008.2549340724945\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 4650, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4651: 0.13330698013305664 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4652: 0.22483661770820618 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4653: 0.13272006809711456 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4654: 0.17475321888923645 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4655: 0.1209540143609047 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4656: 0.22556515038013458 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4657: 0.1328725814819336 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4658: 0.13808080554008484 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4659: 0.12149234116077423 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4660: 0.20379337668418884 \n",
            "\n",
            "Time for 4660 iterations: 1010.3885598182678\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4660, training loss: 0.20,\n",
            "-------------\n",
            "Loss after iteration 4661: 0.15615662932395935 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4662: 0.11342954635620117 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4663: 0.17243586480617523 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4664: 0.19320890307426453 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4665: 0.1495903581380844 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4666: 0.11812089383602142 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4667: 0.14852555096149445 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4668: 0.10752930492162704 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4669: 0.1686643362045288 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4670: 0.14210379123687744 \n",
            "\n",
            "Time for 4670 iterations: 1012.527649641037\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4670, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4671: 0.20358169078826904 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4672: 0.1544342339038849 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4673: 0.17938461899757385 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4674: 0.11193941533565521 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4675: 0.1468546986579895 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4676: 0.1727258861064911 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4677: 0.14444798231124878 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4678: 0.1972018927335739 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4679: 0.13861927390098572 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4680: 0.16643771529197693 \n",
            "\n",
            "Time for 4680 iterations: 1014.6285946369171\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4680, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 4681: 0.2634561359882355 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4682: 0.11918234825134277 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4683: 0.11937154829502106 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4684: 0.19400662183761597 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4685: 0.13770070672035217 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4686: 0.1880468726158142 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4687: 0.18089696764945984 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4688: 0.1506827175617218 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4689: 0.12818245589733124 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4690: 0.16201168298721313 \n",
            "\n",
            "Time for 4690 iterations: 1016.7427895069122\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4690, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4691: 0.17334164679050446 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4692: 0.11410125344991684 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4693: 0.21390032768249512 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4694: 0.1374097466468811 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4695: 0.12147019058465958 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4696: 0.13073639571666718 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4697: 0.17023488879203796 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4698: 0.15194734930992126 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4699: 0.11597329378128052 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4700: 0.19112640619277954 \n",
            "\n",
            "Time for 4700 iterations: 1018.8548905849457\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4700, training loss: 0.19,\n",
            "-------------\n",
            "Loss after iteration 4701: 0.152152419090271 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4702: 0.11401991546154022 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4703: 0.11565828323364258 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4704: 0.1739603728055954 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4705: 0.1304464042186737 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4706: 0.11776787042617798 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4707: 0.22114591300487518 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4708: 0.11435570567846298 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4709: 0.1321999728679657 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4710: 0.13061955571174622 \n",
            "\n",
            "Time for 4710 iterations: 1020.9730348587036\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4710, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4711: 0.11425715684890747 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4712: 0.17630738019943237 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4713: 0.1948755979537964 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4714: 0.11526449024677277 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4715: 0.15893444418907166 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4716: 0.1437169313430786 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4717: 0.15601946413516998 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4718: 0.13472819328308105 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4719: 0.1893535554409027 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4720: 0.15216456353664398 \n",
            "\n",
            "Time for 4720 iterations: 1023.1139299869537\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4720, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4721: 0.17964094877243042 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4722: 0.13093514740467072 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4723: 0.12545877695083618 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4724: 0.13534778356552124 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4725: 0.151085764169693 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4726: 0.16330847144126892 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4727: 0.20022709667682648 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4728: 0.13929161429405212 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4729: 0.1521603763103485 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4730: 0.27285036444664 \n",
            "\n",
            "Time for 4730 iterations: 1025.219494819641\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4730, training loss: 0.27,\n",
            "-------------\n",
            "Loss after iteration 4731: 0.150669664144516 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4732: 0.13650274276733398 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4733: 0.13290897011756897 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4734: 0.12253312766551971 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4735: 0.14468863606452942 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4736: 0.12545478343963623 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4737: 0.15629427134990692 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4738: 0.11633084714412689 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4739: 0.12760713696479797 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4740: 0.10431332886219025 \n",
            "\n",
            "Time for 4740 iterations: 1027.3215372562408\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 4740, training loss: 0.10,\n",
            "-------------\n",
            "Loss after iteration 4741: 0.12260735034942627 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4742: 0.13207855820655823 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4743: 0.12755483388900757 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4744: 0.1066022664308548 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4745: 0.13780422508716583 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4746: 0.1103091686964035 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4747: 0.16989006102085114 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4748: 0.11320576816797256 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4749: 0.16017095744609833 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4750: 0.16531959176063538 \n",
            "\n",
            "Time for 4750 iterations: 1029.4166843891144\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4750, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 4751: 0.1698671579360962 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4752: 0.14538545906543732 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4753: 0.1715490221977234 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4754: 0.1845676600933075 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4755: 0.15570613741874695 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4756: 0.13428202271461487 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4757: 0.11512746661901474 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4758: 0.11204387992620468 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4759: 0.165663480758667 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4760: 0.15429431200027466 \n",
            "\n",
            "Time for 4760 iterations: 1031.567762374878\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 0.0% 10 way one-shot learning accuracy \n",
            "iteration 4760, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4761: 0.12857688963413239 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4762: 0.22913041710853577 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4763: 0.13840144872665405 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4764: 0.12367192655801773 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4765: 0.1171589121222496 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4766: 0.11425383388996124 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4767: 0.10402195155620575 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4768: 0.11096958816051483 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4769: 0.12253524363040924 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4770: 0.12748540937900543 \n",
            "\n",
            "Time for 4770 iterations: 1033.6558418273926\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4770, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4771: 0.18139487504959106 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4772: 0.1241803765296936 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4773: 0.15891164541244507 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4774: 0.14985518157482147 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4775: 0.14652377367019653 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4776: 0.2619404196739197 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4777: 0.11174263805150986 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4778: 0.14435428380966187 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4779: 0.12929858267307281 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4780: 0.1676117181777954 \n",
            "\n",
            "Time for 4780 iterations: 1035.7528417110443\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4780, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 4781: 0.10869987308979034 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4782: 0.17106615006923676 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4783: 0.2448626011610031 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4784: 0.14300289750099182 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4785: 0.12669184803962708 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4786: 0.11546631157398224 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4787: 0.14899009466171265 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4788: 0.13874197006225586 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4789: 0.14796790480613708 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4790: 0.13112804293632507 \n",
            "\n",
            "Time for 4790 iterations: 1037.8463525772095\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4790, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4791: 0.12990888953208923 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4792: 0.1653624176979065 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4793: 0.17881673574447632 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4794: 0.10749010741710663 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4795: 0.14574816823005676 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4796: 0.10265002399682999 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4797: 0.16430184245109558 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4798: 0.1518157720565796 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4799: 0.17053426802158356 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4800: 0.1433117538690567 \n",
            "\n",
            "Time for 4800 iterations: 1039.974758863449\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4800, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4801: 0.131243497133255 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4802: 0.11660885810852051 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4803: 0.15492987632751465 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4804: 0.23864130675792694 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4805: 0.22632992267608643 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4806: 0.22504034638404846 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4807: 0.13658708333969116 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4808: 0.18276505172252655 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4809: 0.12032346427440643 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4810: 0.12545467913150787 \n",
            "\n",
            "Time for 4810 iterations: 1042.1056821346283\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4810, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4811: 0.11184539645910263 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4812: 0.11784745752811432 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4813: 0.11312190443277359 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4814: 0.17055797576904297 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4815: 0.16541340947151184 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4816: 0.23171420395374298 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4817: 0.2132355272769928 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4818: 0.3161652684211731 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4819: 0.14658236503601074 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4820: 0.16172480583190918 \n",
            "\n",
            "Time for 4820 iterations: 1044.2540533542633\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 4820, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4821: 0.13091474771499634 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4822: 0.13594652712345123 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4823: 0.13305805623531342 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4824: 0.29378271102905273 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4825: 0.15260139107704163 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4826: 0.14912457764148712 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4827: 0.1227341741323471 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4828: 0.11710526794195175 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4829: 0.14248403906822205 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4830: 0.14157727360725403 \n",
            "\n",
            "Time for 4830 iterations: 1046.3447484970093\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4830, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4831: 0.1265542209148407 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4832: 0.11387161910533905 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4833: 0.13633085787296295 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4834: 0.12730984389781952 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4835: 0.1349206119775772 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4836: 0.11921534687280655 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4837: 0.10068227350711823 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4838: 0.15119826793670654 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4839: 0.17088830471038818 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4840: 0.11313320696353912 \n",
            "\n",
            "Time for 4840 iterations: 1048.6227443218231\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4840, training loss: 0.11,\n",
            "-------------\n",
            "Loss after iteration 4841: 0.12180297076702118 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4842: 0.15570975840091705 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4843: 0.13042066991329193 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4844: 0.12937308847904205 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4845: 0.3063126802444458 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4846: 0.1228279322385788 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4847: 0.16381458938121796 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4848: 0.1162833422422409 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4849: 0.14707119762897491 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4850: 0.1452617049217224 \n",
            "\n",
            "Time for 4850 iterations: 1050.7708308696747\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4850, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4851: 0.14629404246807098 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4852: 0.1752329170703888 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4853: 0.10266729444265366 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4854: 0.13128426671028137 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4855: 0.15849265456199646 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4856: 0.14889578521251678 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4857: 0.15041039884090424 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4858: 0.15808627009391785 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4859: 0.12577688694000244 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4860: 0.10304632037878036 \n",
            "\n",
            "Time for 4860 iterations: 1052.911996126175\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4860, training loss: 0.10,\n",
            "-------------\n",
            "Loss after iteration 4861: 0.16349586844444275 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4862: 0.1043102964758873 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4863: 0.13689780235290527 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4864: 0.12930408120155334 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4865: 0.13000287115573883 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4866: 0.12162530422210693 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4867: 0.12759467959403992 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4868: 0.10422514379024506 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4869: 0.24675731360912323 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4870: 0.15853828191757202 \n",
            "\n",
            "Time for 4870 iterations: 1055.0723145008087\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 4870, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4871: 0.12581507861614227 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4872: 0.1239154115319252 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4873: 0.10941006988286972 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4874: 0.15847453474998474 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4875: 0.12259630858898163 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4876: 0.16494864225387573 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4877: 0.15007856488227844 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4878: 0.21847672760486603 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4879: 0.12510591745376587 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4880: 0.23729082942008972 \n",
            "\n",
            "Time for 4880 iterations: 1057.1840918064117\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4880, training loss: 0.24,\n",
            "-------------\n",
            "Loss after iteration 4881: 0.11766184866428375 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4882: 0.22405247390270233 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4883: 0.1314011961221695 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4884: 0.1625683605670929 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4885: 0.1976376175880432 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4886: 0.12129268795251846 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4887: 0.14802856743335724 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4888: 0.20410022139549255 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4889: 0.12375614792108536 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4890: 0.1442369967699051 \n",
            "\n",
            "Time for 4890 iterations: 1059.3434312343597\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4890, training loss: 0.14,\n",
            "-------------\n",
            "Loss after iteration 4891: 0.10918627679347992 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4892: 0.11785708367824554 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4893: 0.15268221497535706 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4894: 0.14903782308101654 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4895: 0.15015892684459686 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4896: 0.10998038947582245 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4897: 0.1494957059621811 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4898: 0.1722792685031891 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4899: 0.12246999889612198 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4900: 0.12575304508209229 \n",
            "\n",
            "Time for 4900 iterations: 1061.4861114025116\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4900, training loss: 0.13,\n",
            "-------------\n",
            "Loss after iteration 4901: 0.14892762899398804 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4902: 0.11264296621084213 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4903: 0.175917848944664 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4904: 0.09946051239967346 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4905: 0.11230848729610443 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4906: 0.12366567552089691 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4907: 0.2271834909915924 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4908: 0.1336914300918579 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4909: 0.14229117333889008 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4910: 0.12474721670150757 \n",
            "\n",
            "Time for 4910 iterations: 1063.6536526679993\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4910, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 4911: 0.10029277950525284 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4912: 0.13726398348808289 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4913: 0.17051884531974792 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4914: 0.19987067580223083 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4915: 0.14692141115665436 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4916: 0.14057131111621857 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4917: 0.1544521600008011 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4918: 0.2213527411222458 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4919: 0.16156557202339172 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4920: 0.14943115413188934 \n",
            "\n",
            "Time for 4920 iterations: 1065.8131070137024\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4920, training loss: 0.15,\n",
            "-------------\n",
            "Loss after iteration 4921: 0.1523800939321518 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4922: 0.15307730436325073 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4923: 0.15661078691482544 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4924: 0.17131155729293823 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4925: 0.19081969559192657 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4926: 0.2518051564693451 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4927: 0.1252679079771042 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4928: 0.1445215344429016 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4929: 0.18362683057785034 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4930: 0.40610694885253906 \n",
            "\n",
            "Time for 4930 iterations: 1068.0269556045532\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 24.0% 10 way one-shot learning accuracy \n",
            "iteration 4930, training loss: 0.41,\n",
            "-------------\n",
            "Loss after iteration 4931: 0.2197028398513794 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4932: 0.14878159761428833 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4933: 0.16207164525985718 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4934: 0.1345478743314743 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4935: 0.1406494677066803 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4936: 0.24285325407981873 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4937: 0.10707150399684906 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4938: 0.28890717029571533 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4939: 0.12262170016765594 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4940: 0.17225022614002228 \n",
            "\n",
            "Time for 4940 iterations: 1070.1868739128113\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 20.0% 10 way one-shot learning accuracy \n",
            "iteration 4940, training loss: 0.17,\n",
            "-------------\n",
            "Loss after iteration 4941: 0.1389208734035492 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4942: 0.14816680550575256 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4943: 0.1381997913122177 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4944: 0.1566556692123413 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4945: 0.11437876522541046 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4946: 0.21376168727874756 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4947: 0.17853191494941711 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4948: 0.10454288870096207 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4949: 0.10390255600214005 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4950: 0.12270550429821014 \n",
            "\n",
            "Time for 4950 iterations: 1072.3648319244385\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 4.0% 10 way one-shot learning accuracy \n",
            "iteration 4950, training loss: 0.12,\n",
            "-------------\n",
            "Loss after iteration 4951: 0.15080586075782776 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4952: 0.15313172340393066 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4953: 0.12026107311248779 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4954: 0.13143233954906464 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4955: 0.15087100863456726 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4956: 0.10898218303918839 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4957: 0.10176737606525421 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4958: 0.1420852392911911 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4959: 0.130141481757164 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4960: 0.11060556024312973 \n",
            "\n",
            "Time for 4960 iterations: 1074.5026080608368\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4960, training loss: 0.11,\n",
            "-------------\n",
            "Loss after iteration 4961: 0.12485124915838242 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4962: 0.1232905164361 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4963: 0.13933530449867249 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4964: 0.13098807632923126 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4965: 0.12100403010845184 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4966: 0.12489257007837296 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4967: 0.1080915555357933 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4968: 0.10485098510980606 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4969: 0.12388099730014801 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4970: 0.15555813908576965 \n",
            "\n",
            "Time for 4970 iterations: 1076.632247686386\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 12.0% 10 way one-shot learning accuracy \n",
            "iteration 4970, training loss: 0.16,\n",
            "-------------\n",
            "Loss after iteration 4971: 0.14358538389205933 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4972: 0.13802707195281982 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4973: 0.19981244206428528 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4974: 0.1347806602716446 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4975: 0.1531389355659485 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4976: 0.1357450783252716 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4977: 0.11813972145318985 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4978: 0.1508609652519226 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4979: 0.14021611213684082 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4980: 0.1116347461938858 \n",
            "\n",
            "Time for 4980 iterations: 1078.7533316612244\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 16.0% 10 way one-shot learning accuracy \n",
            "iteration 4980, training loss: 0.11,\n",
            "-------------\n",
            "Loss after iteration 4981: 0.11259348690509796 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4982: 0.1431032121181488 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4983: 0.12865504622459412 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4984: 0.11377359926700592 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4985: 0.11000563204288483 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4986: 0.09807351231575012 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4987: 0.12829555571079254 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4988: 0.21572864055633545 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4989: 0.12451770156621933 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4990: 0.10629583895206451 \n",
            "\n",
            "Time for 4990 iterations: 1080.8959851264954\n",
            "Evaluating model on 25 random 10 way one-shot learning tasks ... \n",
            "Got an average of 8.0% 10 way one-shot learning accuracy \n",
            "iteration 4990, training loss: 0.11,\n",
            "-------------\n",
            "Loss after iteration 4991: 0.1287299394607544 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4992: 0.12017414718866348 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4993: 0.12335915863513947 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4994: 0.19887876510620117 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4995: 0.10527350753545761 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4996: 0.11069657653570175 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4997: 0.1104200929403305 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4998: 0.11753498017787933 \n",
            "\n",
            "-------------\n",
            "Loss after iteration 4999: 0.17281487584114075 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LiJhMhfchkS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "3ecfb405-b4e5-45e7-f5cb-fe3e153974ee"
      },
      "source": [
        "plt.plot(losses,label = 'losses')\n",
        "plt.plot(val_accs,label = 'validation-accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f02ac364710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Mwd9VoS-kG",
        "colab_type": "text"
      },
      "source": [
        "# TESTING THE MODEL WITH N-WAY LEARNING METRICS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A42-0waPAfaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "0124d393-040e-4739-d5ec-c85593406bae"
      },
      "source": [
        " # TESTING THE MODEL \n",
        " \n",
        "def nearest_neighbour_correct(pairs,targets):\n",
        "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
        "        given by (pairs, targets)\"\"\"\n",
        "    L2_distances = np.zeros_like(targets)\n",
        "    for i in range(len(targets)):\n",
        "        L2_distances[i] = np.sum(np.sqrt(pairs[0][i]**2 - pairs[1][i]**2))\n",
        "    if np.argmin(L2_distances) == np.argmax(targets):\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "def test_nn_accuracy(N_ways,n_trials):\n",
        "    \"\"\"Returns accuracy of one shot \"\"\"\n",
        "    print(\"Evaluating nearest neighbour on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
        "\n",
        "    n_right = 0\n",
        "    \n",
        "    for i in range(n_trials):\n",
        "        pairs,targets = make_oneshot_task(N_ways,\"val\")\n",
        "        correct = nearest_neighbour_correct(pairs,targets)\n",
        "        n_right += correct\n",
        "    return 100.0 * n_right / n_trials\n",
        "\n",
        "\n",
        "ways = np.arange(1, 15, 2)\n",
        "resume =  False\n",
        "validation_accs, train_accs,nn_accs = [], [], []\n",
        "trials = 450\n",
        "for N in ways:\n",
        "    validation_accs.append(test_oneshot(model, N,trials, \"val\", verbose=True))\n",
        "    train_accs.append(test_oneshot(model, N,trials, \"train\", verbose=True))\n",
        "    nn_accs.append(test_nn_accuracy(N,trials))\n",
        "    \n",
        "#plot the accuracy vs num categories for each\n",
        "plt.plot(ways, validation_accs, \"m\")\n",
        "plt.plot(ways, train_accs, \"y\")\n",
        "plt.plot(ways, nn_accs, \"c\")\n",
        "\n",
        "plt.plot(ways,100.0/ways,\"r\")\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model on 450 random 1 way one-shot learning tasks ... \n",
            "Got an average of 100.0% 1 way one-shot learning accuracy \n",
            "Evaluating model on 450 random 1 way one-shot learning tasks ... \n",
            "Got an average of 100.0% 1 way one-shot learning accuracy \n",
            "Evaluating nearest neighbour on 450 unique 1 way one-shot learning tasks ...\n",
            "Evaluating model on 450 random 3 way one-shot learning tasks ... \n",
            "Got an average of 29.555555555555557% 3 way one-shot learning accuracy \n",
            "Evaluating model on 450 random 3 way one-shot learning tasks ... \n",
            "Got an average of 99.55555555555556% 3 way one-shot learning accuracy \n",
            "Evaluating nearest neighbour on 450 unique 3 way one-shot learning tasks ...\n",
            "Evaluating model on 450 random 5 way one-shot learning tasks ... \n",
            "Got an average of 16.22222222222222% 5 way one-shot learning accuracy \n",
            "Evaluating model on 450 random 5 way one-shot learning tasks ... \n",
            "Got an average of 99.55555555555556% 5 way one-shot learning accuracy \n",
            "Evaluating nearest neighbour on 450 unique 5 way one-shot learning tasks ...\n",
            "Evaluating model on 450 random 7 way one-shot learning tasks ... \n",
            "Got an average of 11.777777777777779% 7 way one-shot learning accuracy \n",
            "Evaluating model on 450 random 7 way one-shot learning tasks ... \n",
            "Got an average of 99.33333333333333% 7 way one-shot learning accuracy \n",
            "Evaluating nearest neighbour on 450 unique 7 way one-shot learning tasks ...\n",
            "Evaluating model on 450 random 9 way one-shot learning tasks ... \n",
            "Got an average of 9.555555555555555% 9 way one-shot learning accuracy \n",
            "Evaluating model on 450 random 9 way one-shot learning tasks ... \n",
            "Got an average of 98.66666666666667% 9 way one-shot learning accuracy \n",
            "Evaluating nearest neighbour on 450 unique 9 way one-shot learning tasks ...\n",
            "Evaluating model on 450 random 11 way one-shot learning tasks ... \n",
            "Got an average of 9.11111111111111% 11 way one-shot learning accuracy \n",
            "Evaluating model on 450 random 11 way one-shot learning tasks ... \n",
            "Got an average of 99.77777777777777% 11 way one-shot learning accuracy \n",
            "Evaluating nearest neighbour on 450 unique 11 way one-shot learning tasks ...\n",
            "Evaluating model on 450 random 13 way one-shot learning tasks ... \n",
            "Got an average of 9.555555555555555% 13 way one-shot learning accuracy \n",
            "Evaluating model on 450 random 13 way one-shot learning tasks ... \n",
            "Got an average of 98.0% 13 way one-shot learning accuracy \n",
            "Evaluating nearest neighbour on 450 unique 13 way one-shot learning tasks ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyGggszcG3NM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}